# GI Endoscopy AI Diagnostic Platform

A modern, production-ready platform for AI-assisted gastrointestinal (GI) endoscopy image diagnosis with explainable visualizations (Grad-CAM). This repository contains both the Python backend (inference + explainability) and the React frontend (UI for uploads, controls, and visualizations). Docker files and quick-deploy scripts are included for smooth setup.

## Highlights

- Powerful inference API over state-of-the-art vision models (ViT, DeiT3 traced)
- Grad-CAM heatmaps and advanced visualization controls for explainability
- Full-stack: Python FastAPI backend + React/Tailwind frontend
- One-command local run and Docker-based deployment
- Cross-platform quick start scripts for Windows and Linux/macOS

## Architecture

- `backend/`: Python app that loads traced models and serves endpoints for prediction and heatmaps.
- `frontend/`: React SPA with TailwindCSS that interacts with the backend to upload images, select models, and view results.
- `docker-compose.yml`: Development docker-compose for running both services together.
- `docker-compose.prod.yml`: Production-ready compose with Nginx.

See `PROJECT_STRUCTURE.md` for a deeper breakdown.

## Requirements

- Python `3.10+`
- Node.js `18+`
- Docker `24+` (optional, recommended)
- Git

## Quick Start

### Option A: Local (no Docker)

Backend:
```cmd
cd backend
python -m venv .venv
.venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt
python app_gradcam.py
```

Frontend (in a second terminal):
```cmd
cd frontend
npm install
npm start
```

By default, the frontend runs on `http://localhost:3000` and expects the backend at `http://localhost:8000` (adjust if needed).

### Option B: Docker Compose (dev)

```cmd
docker compose up --build
```

This spins up both services. Edit `docker-compose.yml` if you need to customize ports or environment variables.

### Option C: Production Compose

```cmd
docker compose -f docker-compose.prod.yml up --build -d
```

## Scripts

- `start_backend.bat`: Start backend locally on Windows.
- `start_frontend.bat`: Start frontend locally on Windows.
- `deploy.sh` / `deploy.bat`: Quick deploy helpers; see `QUICK_DEPLOY.md` and `DEPLOYMENT.md`.

## API Overview

The backend serves endpoints for:
- Image inference: returns predictions for uploaded endoscopy images.
- Grad-CAM: returns heatmap overlays for explainability.

Refer to `backend/README.md` for exact routes and payload examples.

## Configuration

- Models: Place your traced `.pt` files in `backend/models/`. Defaults: `vit_best_traced.pt`, `deit3_best_traced.pt`.
- Nginx: See `frontend/nginx.conf` for production reverse proxy.
- Tailwind: tweak `frontend/tailwind.config.js` and `postcss.config.js` for styling.

## Troubleshooting

- If GPU/torch issues arise, pin CUDA/torch versions in `backend/requirements.txt`.
- On Windows, ensure you activate the virtual environment: `.venv\Scripts\activate`.
- For CORS or proxy problems, check `frontend/README.md` and `nginx.conf`.

## Roadmap

- Dataset management and evaluation dashboards
- Multi-model ensemble and confidence calibration
- Role-based auth and secure upload storage

## License

Proprietary. All rights reserved.
**For production deployment options, see `DEPLOYMENT.md`**

### Prerequisites

- Python 3.10+
- Node.js 16+ and npm
- CUDA-capable GPU (optional, for faster inference)
- TorchScript model files (place in `backend/models/`)

### 1Ô∏è‚É£ Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment (recommended)
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Place your TorchScript models in backend/models/
# - deit3_best_traced.pt
# - vit_best_traced.pt

# Start the backend server
uvicorn app_gradcam:app --reload --port 8000
```

The backend will be available at `http://127.0.0.1:8000`

**Note**: The backend will work even without model files, but predictions won't be available. Make sure to add your trained TorchScript models to `backend/models/`.

### 2Ô∏è‚É£ Frontend Setup

```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install

# Start the development server
npm start
```

The frontend will open at `http://localhost:3000`

### 3Ô∏è‚É£ Using Docker (Optional)

#### Backend Docker Setup

```bash
cd backend
docker build -t gi-endoscopy-backend .
docker run -p 8000:8000 -v $(pwd)/models:/app/models gi-endoscopy-backend
```

## üìñ API Documentation

### Endpoints

#### `POST /predict`
Upload an endoscopy image for diagnosis.

**Request:**
- Content-Type: `multipart/form-data`
- Body: Image file (PNG, JPG, JPEG)

**Response:**
```json
{
  "predicted_class": "polyps",
  "confidence": 95.23,
  "top3": [
    {"class": "polyps", "confidence": 0.9523},
    {"class": "dyed-lifted-polyps", "confidence": 0.0345},
    {"class": "cecum", "confidence": 0.0089}
  ],
  "gradcam_base64": "base64_encoded_image_string",
  "inference_time": 0.45
}
```

#### `GET /`
Health check endpoint.

#### `GET /health`
Detailed health status including model availability.

## üé® Frontend Features

- **Drag & Drop Upload**: Easy image upload interface
- **Real-time Preview**: See your image before analysis
- **Grad-CAM Visualization**: Interactive heatmap overlay
- **Confidence Scores**: Clear percentage displays
- **Top-3 Predictions**: See alternative diagnoses
- **Responsive Design**: Works on desktop, tablet, and mobile

## üîß Configuration

### Backend Configuration

Edit `backend/app_gradcam.py` to customize:
- `IMG_SIZE`: Input image size (default: 384)
- `CLASS_MAPPING`: Disease class mappings
- `MODEL_PATHS`: Model file locations

### Frontend Configuration

Create `frontend/.env` to set:
```env
REACT_APP_API_URL=http://127.0.0.1:8000
```

## üß™ Model Requirements

Your TorchScript models should:
- Accept input tensor of shape `[1, 3, 384, 384]`
- Output logits of shape `[1, 23]` (23 classes)
- Be saved using `torch.jit.script()` or `torch.jit.trace()`

### Converting Models to TorchScript

```python
import torch

# Load your trained model
model = YourTrainedModel()
model.eval()

# Create example input
example = torch.rand(1, 3, 384, 384)

# Trace the model
traced_model = torch.jit.trace(model, example)

# Save
traced_model.save("models/your_model_traced.pt")
```

## üêõ Troubleshooting

### Backend Issues

**Models not loading:**
- Ensure model files are in `backend/models/` directory
- Check file names match `MODEL_PATHS` in `app_gradcam.py`
- Verify models are valid TorchScript files

**CUDA errors:**
- The backend automatically falls back to CPU if CUDA is unavailable
- Check GPU drivers if you want GPU acceleration

**Grad-CAM errors:**
- Some model architectures may not support Grad-CAM
- The backend will gracefully fall back to original image if Grad-CAM fails

### Frontend Issues

**Connection errors:**
- Ensure backend is running on port 8000
- Check CORS settings if accessing from different origin
- Verify `REACT_APP_API_URL` in `.env` file

**Build errors:**
- Clear `node_modules` and reinstall: `rm -rf node_modules && npm install`
- Check Node.js version (requires 16+)

## üìä Performance

- **Inference Time**: ~0.3-0.8 seconds (GPU) / ~1-3 seconds (CPU)
- **Accuracy**: 92%+ on test dataset
- **Model Size**: ~100-300 MB per model (depending on architecture)

## üîí Security Notes

- This is a development/demo setup
- For production, implement:
  - Authentication/authorization
  - Rate limiting
  - Input validation
  - HTTPS/TLS encryption
  - Secure file upload handling

## üìù License

This project is provided as-is for educational and research purposes.

## ü§ù Contributing

Contributions are welcome! Please feel free to submit issues or pull requests.

## üìß Support

For issues or questions, please open an issue on the repository.

## üö¢ Deployment

### Quick Deploy Options

1. **Docker Compose** (Local/VPS)
   ```bash
   docker-compose up -d --build
   ```

2. **Railway.app** (Easiest cloud)
   - Connect GitHub repo
   - Auto-deploy backend & frontend

3. **Render.com** (Free tier available)
   - Deploy backend as Web Service
   - Deploy frontend as Static Site

4. **AWS/Azure/GCP** (Enterprise)
   - See `DEPLOYMENT.md` for detailed instructions

For complete deployment instructions, see `DEPLOYMENT.md` or `QUICK_DEPLOY.md`

---

**Built with ‚ù§Ô∏è for medical AI research and education**

